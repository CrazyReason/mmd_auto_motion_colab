{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ch3b4xTdYVV3",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@markdown ■■■■■■■■■■■■■■■■■■\n",
        "\n",
        "#@markdown 初始化openpose\n",
        "\n",
        "#@markdown ■■■■■■■■■■■■■■■■■■\n",
        "\n",
        "#设置版本为1.x\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "tf.__version__\n",
        "\n",
        "! nvcc --version\n",
        "! nvidia-smi\n",
        "\n",
        "! pip install PyQt5\n",
        "\n",
        "import time\n",
        "\n",
        "init_start_time = time.time()\n",
        "\n",
        "\n",
        "#安装 cmake\n",
        "\n",
        "#https://drive.google.com/file/d/1lAXs5X7qMnKQE48I0JqSob4FX1t6-mED/view?usp=sharing\n",
        " \n",
        "file_id = \"1lAXs5X7qMnKQE48I0JqSob4FX1t6-mED\"\n",
        "file_name = \"cmake-3.13.4.zip\"\n",
        "! cd  ./ && curl -sc ./cookie \"https://drive.google.com/uc?export=download&id=$file_id\" > /dev/null\n",
        "code = \"$(awk '/_warning_/ {print $NF}' ./cookie)\"  \n",
        "! cd  ./ && curl -Lb ./cookie \"https://drive.google.com/uc?export=download&confirm=$code&id=$file_id\" -o \"$file_name\"\n",
        "! cd  ./ && unzip cmake-3.13.4.zip\n",
        " \n",
        "! cd cmake-3.13.4 && ./configure && make && sudo make install\n",
        "\n",
        "\n",
        "# 依赖库安装 \n",
        "\n",
        "! sudo apt install caffe-cuda\n",
        "\n",
        "! sudo apt-get --assume-yes update\n",
        "! sudo apt-get --assume-yes install build-essential\n",
        "# OpenCV\n",
        "! sudo apt-get --assume-yes install libopencv-dev\n",
        "# General dependencies\n",
        "! sudo apt-get --assume-yes install libatlas-base-dev libprotobuf-dev libleveldb-dev libsnappy-dev libhdf5-serial-dev protobuf-compiler\n",
        "! sudo apt-get --assume-yes install --no-install-recommends libboost-all-dev\n",
        "# Remaining dependencies, 14.04\n",
        "! sudo apt-get --assume-yes install libgflags-dev libgoogle-glog-dev liblmdb-dev\n",
        "# Python3 libs\n",
        "! sudo apt-get --assume-yes install python3-setuptools python3-dev build-essential\n",
        "! sudo apt-get --assume-yes install python3-pip\n",
        "! sudo -H pip3 install --upgrade numpy protobuf opencv-python\n",
        "# OpenCL Generic\n",
        "! sudo apt-get --assume-yes install opencl-headers ocl-icd-opencl-dev\n",
        "! sudo apt-get --assume-yes install libviennacl-dev\n",
        "\n",
        "\n",
        " # Openpose安装\n",
        "ver_openpose = \"v1.6.0\"\n",
        " \n",
        "#  Openpose の clone\n",
        "! git clone  --depth 1 -b \"$ver_openpose\" https://github.com/CMU-Perceptual-Computing-Lab/openpose.git \n",
        "# ! git clone  --depth 1 https://github.com/CMU-Perceptual-Computing-Lab/openpose.git     \n",
        " \n",
        "#  Openpose の モデルデータDL\n",
        "! cd openpose/models && ./getModels.sh\n",
        "\n",
        "#编译Openpose\n",
        "! cd openpose && rm -r build || true && mkdir build && cd build && cmake .. && make -j`nproc` # example demo usage\n",
        "\n",
        "# 执行示例确认\n",
        "! cd /content/openpose && ./build/examples/openpose/openpose.bin --video examples/media/video.avi --write_json ./output/ --display 0  --write_video ./output/openpose.avi\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#@markdown ■■■■■■■■■■■■■■■■■■\n",
        "\n",
        "#@markdown 其他软件初始化\n",
        "\n",
        "#@markdown ■■■■■■■■■■■■■■■■■■\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "ver_tag = \"ver1.02.01\"\n",
        "\n",
        "# FCRN-DepthPrediction-vmd  clone\n",
        "! git clone  --depth 1 -b \"$ver_tag\" https://github.com/miu200521358/FCRN-DepthPrediction-vmd.git\n",
        "\n",
        "# FCRN-DepthPrediction-vmd 识别深度模型下载\n",
        "\n",
        "# 建立模型数据文件夹\n",
        "! mkdir -p ./FCRN-DepthPrediction-vmd/tensorflow/data\n",
        "\n",
        "# 下载模型数据并解压\n",
        "! cd  ./FCRN-DepthPrediction-vmd/tensorflow/data && wget -c \"http://campar.in.tum.de/files/rupprecht/depthpred/NYU_FCRN-checkpoint.zip\" && unzip NYU_FCRN-checkpoint.zip\n",
        "\n",
        "# 3d-pose-baseline-vmd  clone\n",
        "! git clone  --depth 1 -b \"$ver_tag\" https://github.com/miu200521358/3d-pose-baseline-vmd.git\n",
        "\n",
        "# 3d-pose-baseline-vmd Human3.6M 模型数据DL\n",
        "\n",
        "# 建立Human3.6M模型数据文件夹\n",
        "! mkdir -p ./3d-pose-baseline-vmd/data/h36m\n",
        "\n",
        "# 下载Human3.6M模型数据并解压\n",
        "file_id = \"1W5WoWpCcJvGm4CHoUhfIB0dgXBDCEHHq\"\n",
        "file_name = \"h36m.zip\"\n",
        "! cd  ./ && curl -sc ./cookie \"https://drive.google.com/uc?export=download&id=$file_id\" > /dev/null\n",
        "code = \"$(awk '/_warning_/ {print $NF}' ./cookie)\"  \n",
        "! cd  ./ && curl -Lb ./cookie \"https://drive.google.com/uc?export=download&confirm=$code&id=$file_id\" -o \"$file_name\"\n",
        "! cd  ./ && unzip h36m.zip\n",
        "! mv ./h36m ./3d-pose-baseline-vmd/data/\n",
        "\n",
        "# 3d-pose-baseline-vmd 训练数据\n",
        "\n",
        "# 3d-pose-baseline学习数据文件夹\n",
        "! mkdir -p ./3d-pose-baseline-vmd/experiments\n",
        "\n",
        "# 下载3d-pose-baseline训练后的数据\n",
        "file_id = \"1v7ccpms3ZR8ExWWwVfcSpjMsGscDYH7_\"\n",
        "file_name = \"experiments.zip\"\n",
        "! cd  ./3d-pose-baseline-vmd && curl -sc ./cookie \"https://drive.google.com/uc?export=download&id=$file_id\" > /dev/null\n",
        "code = \"$(awk '/_warning_/ {print $NF}' ./cookie)\"  \n",
        "! cd  ./3d-pose-baseline-vmd && curl -Lb ./cookie \"https://drive.google.com/uc?export=download&confirm=$code&id=$file_id\" -o \"$file_name\"\n",
        "! cd  ./3d-pose-baseline-vmd && unzip experiments.zip\n",
        "\n",
        "\n",
        "# VMD-3d-pose-baseline-multi  clone\n",
        "\n",
        "! git clone  --depth 1 -b \"$ver_tag\" https://github.com/miu200521358/VMD-3d-pose-baseline-multi.git\n",
        "\n",
        "# 安装VMD-3d-pose-baseline-multi 依赖库\n",
        "\n",
        "! sudo apt-get install python3-pyqt5  \n",
        "! sudo apt-get install pyqt5-dev-tools\n",
        "! sudo apt-get install qttools5-dev-tools\n",
        "\n",
        "#安装编码器\n",
        "! sudo apt-get install mkvtoolnix\n",
        "\n",
        "init_elapsed_time = (time.time() - init_start_time) / 60\n",
        "\n",
        "! echo \"■■■■■■■■■■■■■■■■■■■■■■■■\"\n",
        "! echo \"■■所有初始化均已完成\"\n",
        "! echo \"■■\"\n",
        "! echo \"■■处理时间：\" \"$init_elapsed_time\" \"分\"\n",
        "! echo \"■■■■■■■■■■■■■■■■■■■■■■■■\"\n",
        "\n",
        "! echo \"Openpose执行结果\"\n",
        "\n",
        "! ls -l /content/openpose/output\n",
        "\n",
        "\n",
        "\n",
        "#@markdown ■■■■■■■■■■■■■■■■■■\n",
        "\n",
        "#@markdown 执行函数初始化\n",
        "\n",
        "#@markdown ■■■■■■■■■■■■■■■■■■\n",
        "\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import datetime\n",
        "\n",
        "\n",
        "import time\n",
        "import datetime\n",
        "import cv2\n",
        "import shutil\n",
        "import glob\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "static_number_people_max = 1  \n",
        "static_frame_first = 0 \n",
        "static_end_frame_no = -1  \n",
        "static_reverse_specific = \"\" \n",
        "static_order_specific = \"\" \n",
        "static_born_model_csv = \"born/animasa_miku_born.csv\"\n",
        "static_is_ik = 1 \n",
        "static_heel_position = 0.0 \n",
        "static_center_z_scale =   1\n",
        "static_smooth_times =   1\n",
        "static_threshold_pos = 0.5 \n",
        "static_threshold_rot = 3  \n",
        "\n",
        "static_src_input_video = \"\"\n",
        "static_input_video = \"\"\n",
        "\n",
        "#执行文件夹\n",
        "openpose_path = \"/content/openpose\"\n",
        "\n",
        "#输出文件夹\n",
        "base_path = \"/content/output\"\n",
        "output_json = \"/content/output/json\"\n",
        "output_openpose_avi = \"/content/output/openpose.avi\"\n",
        "\n",
        "\n",
        "\n",
        "now_str = \"\"\n",
        "depth_dir_path = \"\"\n",
        "drive_dir_path = \"\"\n",
        "\n",
        "def video_hander(  input_video):\n",
        "  global base_path\n",
        "  print(\"视频名称: \", os.path.basename(input_video))\n",
        "  print(\"视频大小: \", os.path.getsize(input_video))\n",
        "\n",
        "\n",
        "  video = cv2.VideoCapture(input_video)\n",
        "  # 宽\n",
        "  W = video.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
        "  # 高\n",
        "  H = video.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
        "  # 总帧数\n",
        "  count = video.get(cv2.CAP_PROP_FRAME_COUNT)\n",
        "  # fps\n",
        "  fps = video.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "  print(\"宽: {0}, 高: {1}, 总帧数: {2}, fps: {3}\".format(W, H, count, fps))\n",
        "\n",
        "\n",
        "\n",
        "  width = 1280\n",
        "  height = 720\n",
        "\n",
        "  if W != 1280 or (fps != 30 and fps != 60):\n",
        "      print(\"重新编码，因为大小或fps不在范围: \"+ input_video)\n",
        "      \n",
        "      # 縮尺\n",
        "      scale = width / W\n",
        "      \n",
        "      # 高さ\n",
        "      height = int(H * scale)\n",
        "\n",
        "      # 出力ファイルパス\n",
        "      out_name = 'recode_{0}.mp4'.format(\"{0:%Y%m%d_%H%M%S}\".format(datetime.datetime.now()))\n",
        "      out_path = '{0}/{1}'.format(base_path, out_name)\n",
        "      \n",
        "      # try:\n",
        "      #     fourcc = cv2.VideoWriter_fourcc(*\"MP4V\")\n",
        "      #     out = cv2.VideoWriter(out_path, fourcc, 30.0, (width, height), True)\n",
        "      #     # 入力ファイル\n",
        "      #     cap = cv2.VideoCapture(input_video)\n",
        "\n",
        "      #     while(cap.isOpened()):\n",
        "      #         # 動画から1枚キャプチャして読み込む\n",
        "      #         flag, frame = cap.read()  # Capture frame-by-frame\n",
        "\n",
        "      #         # 動画が終わっていたら終了\n",
        "      #         if flag == False:\n",
        "      #             break\n",
        "\n",
        "      #         # 縮小\n",
        "      #         output_frame = cv2.resize(frame, (width, height))\n",
        "\n",
        "      #         # 出力\n",
        "      #         out.write(output_frame)\n",
        "\n",
        "      #     # 終わったら開放\n",
        "      #     out.release()\n",
        "      # except Exception as e:\n",
        "      #     print(\"重新编码失败\", e)\n",
        "\n",
        "      # cap.release()\n",
        "      # cv2.destroyAllWindows()\n",
        "\n",
        "      # ! mkvmerge --default-duration 0:30fps --fix-bitstream-timing-information 0 \"$input_video\" -o temp-video.mkv\n",
        "      # ! ffmpeg -i temp-video.mkv -c:v copy  side_video.mkv\n",
        "      # ! ffmpeg -i side_video.mkv -vf scale=1280:720 \"$out_path\"\n",
        "\n",
        "      ! ffmpeg -i \"$input_video\" -qscale 0 -r 30 -y -vf scale=1280:720 \"$out_path\"\n",
        "      \n",
        "      print('MMD重新生成MP4文件成功', out_path)\n",
        "      input_video_name = out_name\n",
        "\n",
        "      # 入力動画ファイル再設定\n",
        "      input_video = base_path + \"/\"+ input_video_name\n",
        "      \n",
        "      video = cv2.VideoCapture(input_video)\n",
        "      # 幅\n",
        "      W = video.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
        "      # 高さ\n",
        "      H = video.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
        "      # 総フレーム数\n",
        "      count = video.get(cv2.CAP_PROP_FRAME_COUNT)\n",
        "      # fps\n",
        "      fps = video.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "      print(\"【重新生成】宽: {0}, 高: {1}, 总帧数: {2}, fps: {3}, 名字: {4}\".format(W, H, count, fps,input_video_name))\n",
        "  return input_video\n",
        "\n",
        "\n",
        "def run_openpose(input_video,number_people_max,frame_first):\n",
        "  #建立临时文件夹\n",
        "\n",
        "  ! mkdir -p \"$output_json\"\n",
        "  #开始执行\n",
        "  ! cd \"$openpose_path\" && ./build/examples/openpose/openpose.bin --video \"$input_video\" --display 0 --model_pose COCO --write_json \"$output_json\" --write_video \"$output_openpose_avi\" --frame_first \"$frame_first\" --number_people_max \"$number_people_max\"\n",
        "\n",
        "def run_fcrn_depth(input_video,end_frame_no,reverse_specific,order_specific):\n",
        "  global now_str,depth_dir_path,drive_dir_path\n",
        "  now_str = \"{0:%Y%m%d_%H%M%S}\".format(datetime.datetime.now())\n",
        "  ! cd FCRN-DepthPrediction-vmd && python tensorflow/predict_video.py --model_path tensorflow/data/NYU_FCRN.ckpt --video_path \"$input_video\" --json_path \"$output_json\" --interval 10 --reverse_specific \"$reverse_specific\" --order_specific \"$order_specific\" --verbose 1 --now \"$now_str\" --avi_output \"yes\"  --number_people_max \"$number_people_max\" --end_frame_no \"$end_frame_no\"\n",
        "  # 深度結果コピー\n",
        "  depth_dir_path =  output_json + \"_\" + now_str + \"_depth\"\n",
        "  drive_dir_path = base_path + \"/\" + now_str \n",
        "\n",
        "  ! mkdir -p \"$drive_dir_path\"\n",
        "\n",
        "  if os.path.exists( depth_dir_path + \"/error.txt\"):\n",
        "    \n",
        "    # 发生错误\n",
        "    ! cp \"$depth_dir_path\"/error.txt \"$drive_dir_path\"\n",
        "\n",
        "    ! echo \"■■■■■■■■■■■■■■■■■■■■■■■■\"\n",
        "    ! echo \"■■由于发生错误，处理被中断。\"\n",
        "    ! echo \"■■\"\n",
        "    ! echo \"■■■■■■■■■■■■■■■■■■■■■■■■\"\n",
        "\n",
        "    ! echo \"$drive_dir_path\" \"请检查 error.txt 的内容。\"\n",
        "  else:\n",
        "      \n",
        "      ! cp \"$depth_dir_path\"/*.avi \"$drive_dir_path\"\n",
        "      ! cp \"$depth_dir_path\"/message.log \"$drive_dir_path\"\n",
        "      ! cp \"$depth_dir_path\"/reverse_specific.txt \"$drive_dir_path\"\n",
        "      ! cp \"$depth_dir_path\"/order_specific.txt \"$drive_dir_path\"\n",
        "\n",
        "      for i in range(1, number_people_max+1):\n",
        "          ! echo ------------------------------------------\n",
        "          ! echo 3d-pose-baseline-vmd [\"$i\"]\n",
        "          ! echo ------------------------------------------\n",
        "\n",
        "          target_name = \"_\" + now_str + \"_idx0\" + str(i)\n",
        "          target_dir = output_json + target_name\n",
        "\n",
        "          !cd ./3d-pose-baseline-vmd && python src/openpose_3dpose_sandbox_vmd.py --camera_frame --residual --batch_norm --dropout 0.5 --max_norm --evaluateActionWise --use_sh --epochs 200 --load 4874200 --gif_fps 30 --verbose 1 --openpose \"$target_dir\" --person_idx 1    \n",
        "\n",
        "def run_3d_to_vmd(number_people_max,born_model_csv,is_ik,heel_position,center_z_scale,smooth_times,threshold_pos,threshold_rot):\n",
        "  global now_str,depth_dir_path,drive_dir_path\n",
        "  for i in range(1, number_people_max+1):\n",
        "    target_name = \"_\" + now_str + \"_idx0\" + str(i)\n",
        "    target_dir = output_json + target_name\n",
        "    for f in glob.glob(target_dir +\"/*.vmd\"):\n",
        "      ! rm \"$f\"\n",
        "    ! cd ./VMD-3d-pose-baseline-multi && python applications/pos2vmd_multi.py -v 2 -t \"$target_dir\" -b \"$born_model_csv\" -c 30 -z \"$center_z_scale\" -s \"$smooth_times\" -p \"$threshold_pos\" -r \"$threshold_rot\" -k \"$is_ik\" -e \"$heel_position\"\n",
        "\n",
        "    # INDEX別結果コピー\n",
        "    idx_dir_path = drive_dir_path + \"/idx0\" + str(i)\n",
        "    ! mkdir -p \"$idx_dir_path\"\n",
        "    \n",
        "    # 日本語対策でpythonコピー\n",
        "    for f in glob.glob(target_dir +\"/*.vmd\"):\n",
        "        shutil.copy(f, idx_dir_path)\n",
        "        print(f)\n",
        "        files.download(f)\n",
        "    \n",
        "    ! cp \"$target_dir\"/pos.txt \"$idx_dir_path\"\n",
        "    ! cp \"$target_dir\"/start_frame.txt \"$idx_dir_path\"\n",
        "\n",
        "\n",
        "\n",
        "def run_mmd(input_video,number_people_max,frame_first,end_frame_no,reverse_specific,order_specific,born_model_csv,is_ik,heel_position,center_z_scale,smooth_times,threshold_pos,threshold_rot):\n",
        "\n",
        "  global static_input_video,static_number_people_max ,static_frame_first ,static_end_frame_no,static_reverse_specific ,static_order_specific,static_born_model_csv \n",
        "  global static_is_ik,static_heel_position ,static_center_z_scale ,static_smooth_times ,static_threshold_pos ,static_threshold_rot \n",
        "  global base_path,static_src_input_video\n",
        "\n",
        "  start_time = time.time()\n",
        "\n",
        "  video_check= False\n",
        "  openpose_check = False\n",
        "  Fcrn_depth_check = False\n",
        "  pose_to_vmd_check = False\n",
        "\n",
        "#源文件对比\n",
        "  if static_src_input_video != input_video:\n",
        "    video_check = True\n",
        "    openpose_check = True\n",
        "    Fcrn_depth_check = True\n",
        "    pose_to_vmd_check = True\n",
        "\n",
        "  if (static_number_people_max != number_people_max) or (static_frame_first != frame_first):\n",
        "    openpose_check = True\n",
        "    Fcrn_depth_check = True\n",
        "    pose_to_vmd_check = True\n",
        "\n",
        "  if (static_end_frame_no != end_frame_no) or (static_reverse_specific != reverse_specific) or (static_order_specific != order_specific):\n",
        "    Fcrn_depth_check = True\n",
        "    pose_to_vmd_check = True\n",
        "\n",
        "  if (static_born_model_csv != born_model_csv) or (static_is_ik != is_ik) or (static_heel_position != heel_position) or (static_center_z_scale != center_z_scale) or \\\n",
        "    (static_smooth_times != smooth_times) or (static_threshold_pos != threshold_pos) or (static_threshold_rot != threshold_rot):\n",
        "    pose_to_vmd_check = True\n",
        "\n",
        "  #因为视频源文件重置，所以如果无修改需要重命名文件\n",
        "  if video_check:\n",
        "    ! rm -rf \"$base_path\"\n",
        "    ! mkdir -p \"$base_path\"\n",
        "    static_src_input_video = input_video\n",
        "    input_video = video_hander(input_video)\n",
        "    static_input_video = input_video\n",
        "  else:\n",
        "    input_video = static_input_video\n",
        "\n",
        "  if openpose_check:\n",
        "    run_openpose(input_video,number_people_max,frame_first)\n",
        "    static_number_people_max = number_people_max\n",
        "    static_frame_first = frame_first\n",
        "\n",
        "  if Fcrn_depth_check:\n",
        "    run_fcrn_depth(input_video,end_frame_no,reverse_specific,order_specific)\n",
        "    static_end_frame_no =   end_frame_no\n",
        "    static_reverse_specific = reverse_specific\n",
        "    static_order_specific =  order_specific\n",
        "\n",
        "  if pose_to_vmd_check:\n",
        "    run_3d_to_vmd(number_people_max,born_model_csv,is_ik,heel_position,center_z_scale,smooth_times,threshold_pos,threshold_rot)\n",
        "    static_born_model_csv = born_model_csv \n",
        "    static_is_ik = is_ik\n",
        "    static_heel_position = heel_position\n",
        "    static_center_z_scale = center_z_scale\n",
        "    static_smooth_times = smooth_times\n",
        "    static_threshold_pos = threshold_pos\n",
        "    static_threshold_rot = threshold_rot\n",
        "\n",
        "\n",
        "  elapsed_time = (time.time() - start_time) / 60\n",
        "  print( \"■■■■■■■■■■■■■■■■■■■■■■■■\")\n",
        "  print( \"■■所有处理完成\")\n",
        "  print( \"■■\")\n",
        "  print( \"■■处理時間：\" + str(elapsed_time)+ \"分\")\n",
        "  print( \"■■■■■■■■■■■■■■■■■■■■■■■■\")\n",
        "  print( \"\")\n",
        "  print( \"MMD自动跟踪执行结果\")\n",
        "  print( base_path)\n",
        "  ! ls -l \"$base_path\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUJveghqio7K",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@markdown ■■■■■■■■■■■■■■■■■■\n",
        "\n",
        "#@markdown GO GO GO GO 执行本单元格，上传视频\n",
        "\n",
        "#@markdown ■■■■■■■■■■■■■■■■■■\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "\n",
        "\n",
        "#@markdown --- \n",
        "\n",
        "#@markdown ###  输入视频名称\n",
        "#@markdown 可以选择手动拖入视频到文件中(比较快)，然后输入视频文件名，或者直接运行，不输入文件名直接本地上传\n",
        "input_video = \"\"  #@param {type: \"string\"}\n",
        "\n",
        "if input_video == \"\":\n",
        "  uploaded = files.upload()\n",
        "\n",
        "  for fn in uploaded.keys():\n",
        "    print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "        name=fn, length=len(uploaded[fn])))\n",
        "    input_video = fn\n",
        "    input_video = \"/content/\" + input_video \n",
        "\n",
        "print(\"本次执行的转化视频文件名为： \"+input_video)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfGWERo0Vog_",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@markdown 输入用于跟踪图像的参数并执行单元。\n",
        "\n",
        "#@markdown --- \n",
        "\n",
        "#@markdown ### 【O】视频中的最大人数\n",
        "#@markdown 请输入您希望从视频中获得的人数。\n",
        "#@markdown 请与视频中人数尽量保持一致\n",
        "number_people_max =   1#@param {type: \"number\"}\n",
        "\n",
        "#@markdown --- \n",
        "\n",
        "#@markdown ### 【O】要从第几帧开始分析\n",
        "#@markdown 输入帧号以开始分析。（从0开始）\n",
        "#@markdown 请指定在视频中显示所有人的第一帧，默认为0即可，除非你需要跳过某些片段（例如片头）。\n",
        "frame_first = 0  #@param {type: \"number\"}\n",
        "\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown ### 【F】要从第几帧结束\n",
        "#@markdown 请输入要从哪一帧结束\n",
        "#@markdown （从0开始）在“FCRN-DepthPrediction-vmd”中调整反向或顺序时，可以完成过程并查看结果，默认为-1 表示执行到最后\n",
        "end_frame_no = -1  #@param {type: \"number\"}\n",
        "\n",
        "#@markdown --- \n",
        "\n",
        "#@markdown ### 【F】反转数据表\n",
        "#@markdown 指定由Openpose反转的帧号（从0开始），人员INDEX顺序和反转的内容。\n",
        "#@markdown 按照Openpose在 0F 识别的顺序，将INDEX分配为0,1,...。\n",
        "\n",
        "#@markdown 格式: [{帧号}: 用于指定反转的人INDEX, {反转内容}]\n",
        "#@markdown {反转内容}: R: 整体身体反转, U:上半身反转, L: 下半身反转, N: 无反转\n",
        "\n",
        "#@markdown 例如：[10:1,R]　整个人在第10帧中反转第一个人。在message.log中会记录以上述格式输出内容\n",
        "\n",
        "\n",
        "#@markdown 因此请参考与[10:1,R][30:0,U],中一样，可以在括号中指定多个项目 ps(不要带有中文标点符号))\n",
        "reverse_specific = \"\"  #@param {type: \"string\"}\n",
        "\n",
        "#@markdown --- \n",
        "\n",
        "#@markdown ### 【F】输出颜色(仅参考，如果多人时，某个人序号跟别人交换或者错误，可以用此项修改)\n",
        "#@markdown 请在多人轨迹中的交点之后指定人索引顺序。如果要跟踪一个人，可以将其留为空白。\n",
        "#@markdown 按照Openpose在0F时识别的顺序分配0、1和INDEX。格式：[<帧号>：第几个人的索引，第几个人的索引，…]示例）[10:1,0]…第帧10是从左数第1人按第0个人的顺序对其进行排序。\n",
        "#@markdown message.log包含以上述格式输出的顺序，因此请参考它。可以在括号中指定多个项目，例如[10:1,0] [30:0,1]。在output_XXX.avi中，按照估计顺序为人们分配了颜色。身体的右半部分为红色，左半部分为以下颜色。\n",
        "#@markdown 0：绿色，1：蓝色，2：白色，3：黄色，4：桃红色，5：浅蓝色，6：深绿色，7：深蓝色，8：灰色，9：深黄色，​​10：深桃红色，11：深浅蓝色\n",
        "order_specific = \"\"  #@param {type: \"string\"}\n",
        "\n",
        "#@markdown --- \n",
        "\n",
        "#@markdown ### 【V】骨骼结构CSV文件\n",
        "#@markdown 选择或输入跟踪目标模型的骨骼结构CSV文件的路径。请将csv文件上传到Google云端硬盘的“ autotrace”文件夹。\n",
        "#@markdown 您可以选择 \"Animasa-Miku\" 和 \"Animasa-Miku semi-standard\", 也可以输入任何模型的骨骼结构CSV文件\n",
        "#@markdown 如果要输入任何模型骨骼结构CSV文件, 请将csv文件上传到Google云端硬盘的 \"autotrace\" 文件夹下\n",
        "#@markdown 然后请输入「/gdrive/My Drive/autotrace/[csv file name]」\n",
        "born_model_csv = \"born/\\u3042\\u306B\\u307E\\u3055\\u5F0F\\u30DF\\u30AF\\u6E96\\u6A19\\u6E96\\u30DC\\u30FC\\u30F3.csv\" #@param [\"born/animasa_miku_born.csv\", \"born/animasa_miku_semi_standard_born.csv\"] {allow-input: true}\n",
        "\n",
        "\n",
        "#@markdown --- \n",
        "\n",
        "#@markdown ### 【V】是否使用IK输出\n",
        "#@markdown 选择以IK输出，yes或no \n",
        "#@markdown 如果输入no，则以输出FK\n",
        "ik_flag = \"yes\"  #@param ['yes', 'no']\n",
        "is_ik = 1 if ik_flag == \"yes\" else 0\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown ### 【V】脚与地面位置校正\n",
        "#@markdown 请输入数值的鞋跟的Y轴校正值（可以为小数）\n",
        "#@markdown 输入负值会接近地面，输入正值会远离地面。\n",
        "#@markdown 尽管会自动在某种程度上自动校正，但如果无法校正，请进行设置。\n",
        "heel_position = 0.0  #@param {type: \"number\"}\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown ### 【V】Z中心放大倍率\n",
        "#@markdown 以将放大倍数应用到Z轴中心移动（可以是小数）\n",
        "#@markdown 值越小，中心Z移动的宽度越小\n",
        "#@markdown 输入0时，不进行Z轴中心移动。\n",
        "center_z_scale =   2#@param {type: \"number\"}\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown ### 【V】平滑频率\n",
        "#@markdown 指定运动的平滑频率\n",
        "#@markdown 请仅输入1或更大的整数\n",
        "#@markdown 频率越大，频率越平滑。（行为幅度会变小）\n",
        "smooth_times =   1#@param {type: \"number\"}\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown ### 【V】移动稀疏量 (低于该阀值的运动宽度，不会进行输出，防抖动)\n",
        "#@markdown 用数值（允许小数）指定用于稀疏移动（IK /中心）的移动量\n",
        "#@markdown 如果在指定范围内有移动，则将稀疏。如果移动抽取量设置为0，则不执行抽取。\n",
        "#@markdown 当移动稀疏量设置为0时，不进行稀疏。\n",
        "threshold_pos = 0.3  #@param {type: \"number\"}\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown ### 【V】旋转稀疏角 (低于该阀值的运动角度，则不会进行输出)\n",
        "#@markdown 指定用于稀疏旋转键的角度（0到180度的十进制数）\n",
        "#@markdown 如果在指定角度范围内有旋转，则稀疏旋转键。\n",
        "threshold_rot =   3#@param {type: \"number\"}\n",
        "\n",
        "\n",
        "\n",
        "print(\" 【O】Maximum number of people in the video: \"+str(number_people_max))\n",
        "print(\" 【O】Frame number to start analysis: \"+str(frame_first))\n",
        "print(\" 【F】Frame number to finish analysis: \"+str(end_frame_no))\n",
        "print(\" 【F】Reverse specification list: \"+str(reverse_specific))\n",
        "print(\" 【F】Ordered list: \"+str(order_specific))\n",
        "print(\" 【V】Bone structure CSV file: \"+str(born_model_csv))\n",
        "print(\" 【V】Whether to output with IK: \"+str(ik_flag))\n",
        "print(\" 【V】Heel position correction: \"+str(heel_position))\n",
        "print(\" 【V】Center Z moving magnification: \"+str(center_z_scale))\n",
        "print(\" 【V】Smoothing frequency: \"+str(smooth_times))\n",
        "print(\" 【V】Movement key thinning amount: \"+str(threshold_pos))\n",
        "print(\" 【V】Rotating Key Culling Angle: \"+str(threshold_rot))\n",
        "\n",
        "\n",
        "print(\"\")\n",
        "print(\"If the above is correct, please proceed to the next.\")\n",
        "\n",
        "\n",
        "#input_video = \"/content/openpose/examples/media/video.avi\"\n",
        "\n",
        "run_mmd(input_video,number_people_max,frame_first,end_frame_no,reverse_specific,order_specific,born_model_csv,is_ik,heel_position,center_z_scale,smooth_times,threshold_pos,threshold_rot)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5BTajiNP8x-I",
        "colab_type": "text"
      },
      "source": [
        "# License许可"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EH-Jfo6x7pgc",
        "colab_type": "text"
      },
      "source": [
        "发布和分发MMD自动跟踪的结果时，请确保检查许可证。Unity也是如此。\n",
        "\n",
        "如果您能列出您的许可证，我将不胜感激。\n",
        "[MMD运动跟踪自动化套件许可证](https://ch.nicovideo.jp/miu200521358/blomaga/ar1686913)\n",
        "\n",
        "原作者:Twitter miu200521358\n",
        "\n",
        "修改与优化:B站 妖风瑟瑟\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "auto_mmd_vmd_run_v1.02.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}